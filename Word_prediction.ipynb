{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWYhDEEFef7dRa4A4ZRTCE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sundar-nallalagappan/Coursera_NLP_assignments/blob/main/Word_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e5i2BSjfJjY",
        "outputId": "79acb043-1f3c-4c2b-d7fb-c2fa57d3754c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sairam\n"
          ]
        }
      ],
      "source": [
        "print(\"sairam\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "N6Mf4EnqfPEZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the lyrics of the song\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUhD1iUffUUw",
        "outputId": "ade0b6d1-891f-427f-8d67-a46e8ff93822"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the town of Athy one Jeremy Lanigan \n",
            " Battered away til he hadnt a pound. \n",
            "His father died and made him a man again \n",
            " Left him a farm and ten acres of ground. \n",
            "He gave a grand party for friends and relations \n",
            "Who didnt forget him when come to the wall, \n",
            "And if youll but listen Ill make your eyes glisten \n",
            "Of the rows and the ructions of Lanigans Ball. \n",
            "Myself to be sure got free invitation, \n",
            "For all the nice girls and boys I might ask, \n",
            "And just in a minute both friends and relations \n",
            "Were dancing round merry as bees round a cask. \n",
            "Judy ODaly, that nice little milliner, \n",
            "She tipped me a wink for to give her a call, \n",
            "And I soon arrived with Peggy McGilligan \n",
            "Just in time for Lanigans Ball. \n",
            "There were lashings of punch and wine for the ladies, \n",
            "Potatoes and cakes; there was bacon and tea, \n",
            "There were the Nolans, Dolans, OGradys \n",
            "Courting the girls and dancing away. \n",
            "Songs they went round as plenty as water, \n",
            "The harp that once sounded in Taras old hall,\n",
            "Sweet Nelly Gray and The Rat Catchers Daughter,\n",
            "All singing together at Lanigans Ball. \n",
            "They were doing all kinds of nonsensical polkas \n",
            "All round the room in a whirligig. \n",
            "Julia and I, we banished their nonsense \n",
            "And tipped them the twist of a reel and a jig. \n",
            "Ach mavrone, how the girls got all mad at me \n",
            "Danced til youd think the ceiling would fall. \n",
            "For I spent three weeks at Brooks Academy \n",
            "Learning new steps for Lanigans Ball. \n",
            "Three long weeks I spent up in Dublin, \n",
            "Three long weeks to learn nothing at all,\n",
            " Three long weeks I spent up in Dublin, \n",
            "Learning new steps for Lanigans Ball. \n",
            "She stepped out and I stepped in again, \n",
            "I stepped out and she stepped in again, \n",
            "She stepped out and I stepped in again, \n",
            "Learning new steps for Lanigans Ball. \n",
            "Boys were all merry and the girls they were hearty \n",
            "And danced all around in couples and groups, \n",
            "Til an accident happened, young Terrance McCarthy \n",
            "Put his right leg through miss Finnertys hoops. \n",
            "Poor creature fainted and cried Meelia murther, \n",
            "Called for her brothers and gathered them all. \n",
            "Carmody swore that hed go no further \n",
            "Til he had satisfaction at Lanigans Ball. \n",
            "In the midst of the row miss Kerrigan fainted, \n",
            "Her cheeks at the same time as red as a rose. \n",
            "Some of the lads declared she was painted, \n",
            "She took a small drop too much, I suppose. \n",
            "Her sweetheart, Ned Morgan, so powerful and able, \n",
            "When he saw his fair colleen stretched out by the wall, \n",
            "Tore the left leg from under the table \n",
            "And smashed all the Chaneys at Lanigans Ball. \n",
            "Boys, oh boys, twas then there were runctions. \n",
            "Myself got a lick from big Phelim McHugh. \n",
            "I soon replied to his introduction \n",
            "And kicked up a terrible hullabaloo. \n",
            "Old Casey, the piper, was near being strangled. \n",
            "They squeezed up his pipes, bellows, chanters and all. \n",
            "The girls, in their ribbons, they got all entangled \n",
            "And that put an end to Lanigans Ball.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = data.split('\\n')\n",
        "print(f\"number of sentences: {len(corpus)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6OINYWOfVtx",
        "outputId": "9d457158-730f-43cc-8bde-3cb8ecad0484"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of sentences: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOArm2y9fepW",
        "outputId": "73d7f58a-5c87-409e-8986-674fd2b1d484"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In the town of Athy one Jeremy Lanigan ',\n",
              " ' Battered away til he hadnt a pound. ',\n",
              " 'His father died and made him a man again ',\n",
              " ' Left him a farm and ten acres of ground. ',\n",
              " 'He gave a grand party for friends and relations ']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "print(f\"Number of unique words in vocab {len(word_index)}\")\n",
        "word_index\n",
        "\n",
        "# Define the total words. You add 1 for the index `0` which is just the padding token.\n",
        "total_words = len(word_index) + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87rCL9z8fhdE",
        "outputId": "52915538-a18b-4ee1-ef05-f50026269383"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in vocab 262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "sequences"
      ],
      "metadata": {
        "id": "YQlFd9IWfsB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = np.max([len(row) for row in sequences])"
      ],
      "metadata": {
        "id": "Tt6D12zvhcYp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for row in corpus:\n",
        "  token_text = tokenizer.texts_to_sequences([row])[0]\n",
        "\n",
        "  for i in range(len(token_text)):\n",
        "    n_gram_seq = token_text[:i+1]\n",
        "    input_sequences.append(n_gram_seq)"
      ],
      "metadata": {
        "id": "4mJu_wH5hZOu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "id": "paXzgaD9im7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(input_sequences, maxlen=max_seq_len, padding=\"pre\")\n",
        "padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSQzpCWSinh9",
        "outputId": "b51bba15-7624-45f1-ad3b-f9d7bd90656b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,   4],\n",
              "       [  0,   0,   0, ...,   0,   4,   2],\n",
              "       [  0,   0,   0, ...,   4,   2,  66],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  60, 262,  13],\n",
              "       [  0,   0,   0, ..., 262,  13,   9],\n",
              "       [  0,   0,   0, ...,  13,   9,  10]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnwXYM4Li0zP",
        "outputId": "cadca1da-e26a-4869-92e8-28a9e95e00d9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  2],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  2, 66],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  4,  2, 66,  8],\n",
              "       [ 0,  0,  0,  0,  0,  0,  4,  2, 66,  8, 67],\n",
              "       [ 0,  0,  0,  0,  0,  4,  2, 66,  8, 67, 68],\n",
              "       [ 0,  0,  0,  0,  4,  2, 66,  8, 67, 68, 69],\n",
              "       [ 0,  0,  0,  4,  2, 66,  8, 67, 68, 69, 70],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 71],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 71, 40]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xs = padded[:,:-1]\n",
        "labels = padded[:,-1]\n",
        "\n",
        "Xs.shape, labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyflqXkXkwzR",
        "outputId": "0f52d72c-3e96-4172-ff9e-a307819acfa9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((517, 10), (517,))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "g9C_WLNzlElf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0], Ys[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBAxc76olQll",
        "outputId": "f282f2c4-16a9-4d4b-a3b6-f55a13255d53"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ele = 6\n",
        "print(Xs[ele])\n",
        "print(tokenizer.sequences_to_texts([Xs[ele]]))\n",
        "print(Ys[ele])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_hEGp_2mVYn",
        "outputId": "a66ef90d-790c-4413-ccf2-15d74a372c3b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0  4  2 66  8 67 68]\n",
            "['in the town of athy one']\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.index_word.get(np.argmax(Ys[ele]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AXI_q-oam5dC",
        "outputId": "34d9ec8e-e6fb-4ff8-d30d-e07a6d31b61a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jeremy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "ezPM_YQpnZ1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Ys.shape[1], total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dyE4pBVn54Y",
        "outputId": "990325d7-6e3b-45f9-a0d7-852861e9094a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(263, 263)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_seq_len-1))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(Ys.shape[1], \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVD8giWOnLyG",
        "outputId": "822d9464-2488-4fda-f6b2-82a2268dbc3c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 10, 64)            16832     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               24832     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 263)               17095     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,759\n",
            "Trainable params: 58,759\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(Xs, Ys, epochs=500, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kELvCM_EoNio",
        "outputId": "80c82ab3-e5b0-42a5-8654-cb7e143fe5fb"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "65/65 [==============================] - 5s 11ms/step - loss: 5.5437 - accuracy: 0.0406\n",
            "Epoch 2/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 5.2181 - accuracy: 0.0484\n",
            "Epoch 3/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 5.0557 - accuracy: 0.0580\n",
            "Epoch 4/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 4.9572 - accuracy: 0.0522\n",
            "Epoch 5/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 4.8627 - accuracy: 0.0580\n",
            "Epoch 6/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 4.7546 - accuracy: 0.0522\n",
            "Epoch 7/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 4.6330 - accuracy: 0.0716\n",
            "Epoch 8/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 4.5309 - accuracy: 0.0832\n",
            "Epoch 9/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 4.4216 - accuracy: 0.0870\n",
            "Epoch 10/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 4.3118 - accuracy: 0.1064\n",
            "Epoch 11/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 4.1978 - accuracy: 0.1199\n",
            "Epoch 12/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 4.0791 - accuracy: 0.1315\n",
            "Epoch 13/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 3.9587 - accuracy: 0.1509\n",
            "Epoch 14/500\n",
            "65/65 [==============================] - 1s 10ms/step - loss: 3.8432 - accuracy: 0.1605\n",
            "Epoch 15/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 3.7208 - accuracy: 0.1857\n",
            "Epoch 16/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 3.6013 - accuracy: 0.2205\n",
            "Epoch 17/500\n",
            "65/65 [==============================] - 1s 10ms/step - loss: 3.5001 - accuracy: 0.2437\n",
            "Epoch 18/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 3.3961 - accuracy: 0.2669\n",
            "Epoch 19/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 3.2735 - accuracy: 0.2805\n",
            "Epoch 20/500\n",
            "65/65 [==============================] - 1s 10ms/step - loss: 3.1566 - accuracy: 0.2979\n",
            "Epoch 21/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 3.0573 - accuracy: 0.3269\n",
            "Epoch 22/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.9511 - accuracy: 0.3559\n",
            "Epoch 23/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.8522 - accuracy: 0.3849\n",
            "Epoch 24/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.7603 - accuracy: 0.4004\n",
            "Epoch 25/500\n",
            "65/65 [==============================] - 1s 17ms/step - loss: 2.7229 - accuracy: 0.4081\n",
            "Epoch 26/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 2.6082 - accuracy: 0.4429\n",
            "Epoch 27/500\n",
            "65/65 [==============================] - 1s 17ms/step - loss: 2.5237 - accuracy: 0.4720\n",
            "Epoch 28/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.4365 - accuracy: 0.4836\n",
            "Epoch 29/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.3535 - accuracy: 0.5184\n",
            "Epoch 30/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 2.2842 - accuracy: 0.5280\n",
            "Epoch 31/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.2376 - accuracy: 0.5609\n",
            "Epoch 32/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.1702 - accuracy: 0.5667\n",
            "Epoch 33/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.1179 - accuracy: 0.5938\n",
            "Epoch 34/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 2.0470 - accuracy: 0.6112\n",
            "Epoch 35/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.9870 - accuracy: 0.6035\n",
            "Epoch 36/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.9392 - accuracy: 0.6248\n",
            "Epoch 37/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.8728 - accuracy: 0.6441\n",
            "Epoch 38/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.8383 - accuracy: 0.6499\n",
            "Epoch 39/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.7803 - accuracy: 0.6654\n",
            "Epoch 40/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.7163 - accuracy: 0.6750\n",
            "Epoch 41/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 1.6803 - accuracy: 0.6905\n",
            "Epoch 42/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 1.6165 - accuracy: 0.7137\n",
            "Epoch 43/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 1.5920 - accuracy: 0.7060\n",
            "Epoch 44/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.5494 - accuracy: 0.7099\n",
            "Epoch 45/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.5245 - accuracy: 0.7292\n",
            "Epoch 46/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.4818 - accuracy: 0.7234\n",
            "Epoch 47/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.4347 - accuracy: 0.7389\n",
            "Epoch 48/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.4106 - accuracy: 0.7485\n",
            "Epoch 49/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.3787 - accuracy: 0.7447\n",
            "Epoch 50/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.3686 - accuracy: 0.7447\n",
            "Epoch 51/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.3169 - accuracy: 0.7524\n",
            "Epoch 52/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.2803 - accuracy: 0.7485\n",
            "Epoch 53/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.2433 - accuracy: 0.7776\n",
            "Epoch 54/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.2111 - accuracy: 0.7718\n",
            "Epoch 55/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.2082 - accuracy: 0.7582\n",
            "Epoch 56/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.1674 - accuracy: 0.7795\n",
            "Epoch 57/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 1.1377 - accuracy: 0.8027\n",
            "Epoch 58/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 1.1264 - accuracy: 0.7950\n",
            "Epoch 59/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 1.0937 - accuracy: 0.7969\n",
            "Epoch 60/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 1.0741 - accuracy: 0.7969\n",
            "Epoch 61/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.0553 - accuracy: 0.8066\n",
            "Epoch 62/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 1.0299 - accuracy: 0.8085\n",
            "Epoch 63/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 1.0076 - accuracy: 0.8143\n",
            "Epoch 64/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.9968 - accuracy: 0.8240\n",
            "Epoch 65/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.9736 - accuracy: 0.8182\n",
            "Epoch 66/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.9573 - accuracy: 0.8240\n",
            "Epoch 67/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.9427 - accuracy: 0.8298\n",
            "Epoch 68/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.9490 - accuracy: 0.8221\n",
            "Epoch 69/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.9346 - accuracy: 0.8279\n",
            "Epoch 70/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.9144 - accuracy: 0.8279\n",
            "Epoch 71/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.8907 - accuracy: 0.8356\n",
            "Epoch 72/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.8686 - accuracy: 0.8279\n",
            "Epoch 73/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.8560 - accuracy: 0.8279\n",
            "Epoch 74/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.8352 - accuracy: 0.8356\n",
            "Epoch 75/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.8503 - accuracy: 0.8298\n",
            "Epoch 76/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.8310 - accuracy: 0.8356\n",
            "Epoch 77/500\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.8228 - accuracy: 0.8298\n",
            "Epoch 78/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.8255 - accuracy: 0.8298\n",
            "Epoch 79/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.8212 - accuracy: 0.8240\n",
            "Epoch 80/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.7998 - accuracy: 0.8337\n",
            "Epoch 81/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.7906 - accuracy: 0.8317\n",
            "Epoch 82/500\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.7775 - accuracy: 0.8337\n",
            "Epoch 83/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.7556 - accuracy: 0.8337\n",
            "Epoch 84/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.7388 - accuracy: 0.8395\n",
            "Epoch 85/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.7303 - accuracy: 0.8414\n",
            "Epoch 86/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.7226 - accuracy: 0.8337\n",
            "Epoch 87/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.7150 - accuracy: 0.8375\n",
            "Epoch 88/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.7113 - accuracy: 0.8395\n",
            "Epoch 89/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.7034 - accuracy: 0.8356\n",
            "Epoch 90/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.6988 - accuracy: 0.8356\n",
            "Epoch 91/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.6907 - accuracy: 0.8375\n",
            "Epoch 92/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.6847 - accuracy: 0.8375\n",
            "Epoch 93/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6787 - accuracy: 0.8375\n",
            "Epoch 94/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.6753 - accuracy: 0.8375\n",
            "Epoch 95/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.6691 - accuracy: 0.8337\n",
            "Epoch 96/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.6654 - accuracy: 0.8375\n",
            "Epoch 97/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.6652 - accuracy: 0.8337\n",
            "Epoch 98/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.6642 - accuracy: 0.8414\n",
            "Epoch 99/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.6575 - accuracy: 0.8375\n",
            "Epoch 100/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.6497 - accuracy: 0.8356\n",
            "Epoch 101/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.6572 - accuracy: 0.8395\n",
            "Epoch 102/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.6518 - accuracy: 0.8337\n",
            "Epoch 103/500\n",
            "65/65 [==============================] - 1s 21ms/step - loss: 0.6460 - accuracy: 0.8317\n",
            "Epoch 104/500\n",
            "65/65 [==============================] - 3s 53ms/step - loss: 0.6550 - accuracy: 0.8375\n",
            "Epoch 105/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.7185 - accuracy: 0.8279\n",
            "Epoch 106/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.6944 - accuracy: 0.8298\n",
            "Epoch 107/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.6534 - accuracy: 0.8414\n",
            "Epoch 108/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.6487 - accuracy: 0.8298\n",
            "Epoch 109/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.6316 - accuracy: 0.8375\n",
            "Epoch 110/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6258 - accuracy: 0.8395\n",
            "Epoch 111/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6268 - accuracy: 0.8337\n",
            "Epoch 112/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6169 - accuracy: 0.8337\n",
            "Epoch 113/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.6128 - accuracy: 0.8356\n",
            "Epoch 114/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.6061 - accuracy: 0.8356\n",
            "Epoch 115/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.6041 - accuracy: 0.8317\n",
            "Epoch 116/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5980 - accuracy: 0.8453\n",
            "Epoch 117/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5956 - accuracy: 0.8337\n",
            "Epoch 118/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5946 - accuracy: 0.8414\n",
            "Epoch 119/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5920 - accuracy: 0.8337\n",
            "Epoch 120/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.5904 - accuracy: 0.8414\n",
            "Epoch 121/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.5912 - accuracy: 0.8395\n",
            "Epoch 122/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.5896 - accuracy: 0.8356\n",
            "Epoch 123/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5859 - accuracy: 0.8337\n",
            "Epoch 124/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5838 - accuracy: 0.8414\n",
            "Epoch 125/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.5864 - accuracy: 0.8298\n",
            "Epoch 126/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.5911 - accuracy: 0.8395\n",
            "Epoch 127/500\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.5840 - accuracy: 0.8433\n",
            "Epoch 128/500\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.5822 - accuracy: 0.8453\n",
            "Epoch 129/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5802 - accuracy: 0.8375\n",
            "Epoch 130/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5808 - accuracy: 0.8375\n",
            "Epoch 131/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5793 - accuracy: 0.8433\n",
            "Epoch 132/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5782 - accuracy: 0.8395\n",
            "Epoch 133/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5772 - accuracy: 0.8395\n",
            "Epoch 134/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6189 - accuracy: 0.8317\n",
            "Epoch 135/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6261 - accuracy: 0.8317\n",
            "Epoch 136/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5983 - accuracy: 0.8375\n",
            "Epoch 137/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5928 - accuracy: 0.8356\n",
            "Epoch 138/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5933 - accuracy: 0.8317\n",
            "Epoch 139/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5758 - accuracy: 0.8433\n",
            "Epoch 140/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5689 - accuracy: 0.8433\n",
            "Epoch 141/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5634 - accuracy: 0.8375\n",
            "Epoch 142/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5611 - accuracy: 0.8395\n",
            "Epoch 143/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5608 - accuracy: 0.8395\n",
            "Epoch 144/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5621 - accuracy: 0.8472\n",
            "Epoch 145/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5617 - accuracy: 0.8395\n",
            "Epoch 146/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5587 - accuracy: 0.8433\n",
            "Epoch 147/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5591 - accuracy: 0.8395\n",
            "Epoch 148/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5590 - accuracy: 0.8356\n",
            "Epoch 149/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5540 - accuracy: 0.8453\n",
            "Epoch 150/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5553 - accuracy: 0.8375\n",
            "Epoch 151/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5552 - accuracy: 0.8433\n",
            "Epoch 152/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5534 - accuracy: 0.8395\n",
            "Epoch 153/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5534 - accuracy: 0.8337\n",
            "Epoch 154/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5516 - accuracy: 0.8395\n",
            "Epoch 155/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5498 - accuracy: 0.8414\n",
            "Epoch 156/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5509 - accuracy: 0.8356\n",
            "Epoch 157/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5501 - accuracy: 0.8395\n",
            "Epoch 158/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5489 - accuracy: 0.8395\n",
            "Epoch 159/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5496 - accuracy: 0.8433\n",
            "Epoch 160/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5498 - accuracy: 0.8395\n",
            "Epoch 161/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5499 - accuracy: 0.8375\n",
            "Epoch 162/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5503 - accuracy: 0.8395\n",
            "Epoch 163/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6088 - accuracy: 0.8240\n",
            "Epoch 164/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.7297 - accuracy: 0.7969\n",
            "Epoch 165/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6689 - accuracy: 0.8104\n",
            "Epoch 166/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5920 - accuracy: 0.8317\n",
            "Epoch 167/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5613 - accuracy: 0.8395\n",
            "Epoch 168/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5518 - accuracy: 0.8433\n",
            "Epoch 169/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5496 - accuracy: 0.8472\n",
            "Epoch 170/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5482 - accuracy: 0.8375\n",
            "Epoch 171/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5459 - accuracy: 0.8433\n",
            "Epoch 172/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5457 - accuracy: 0.8433\n",
            "Epoch 173/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5452 - accuracy: 0.8433\n",
            "Epoch 174/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5457 - accuracy: 0.8356\n",
            "Epoch 175/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5448 - accuracy: 0.8337\n",
            "Epoch 176/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5428 - accuracy: 0.8395\n",
            "Epoch 177/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5463 - accuracy: 0.8356\n",
            "Epoch 178/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5472 - accuracy: 0.8433\n",
            "Epoch 179/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5439 - accuracy: 0.8433\n",
            "Epoch 180/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5417 - accuracy: 0.8395\n",
            "Epoch 181/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5408 - accuracy: 0.8375\n",
            "Epoch 182/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5394 - accuracy: 0.8414\n",
            "Epoch 183/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5387 - accuracy: 0.8472\n",
            "Epoch 184/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5395 - accuracy: 0.8433\n",
            "Epoch 185/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5394 - accuracy: 0.8433\n",
            "Epoch 186/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5386 - accuracy: 0.8414\n",
            "Epoch 187/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5389 - accuracy: 0.8395\n",
            "Epoch 188/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5376 - accuracy: 0.8375\n",
            "Epoch 189/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5377 - accuracy: 0.8395\n",
            "Epoch 190/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5378 - accuracy: 0.8395\n",
            "Epoch 191/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5403 - accuracy: 0.8453\n",
            "Epoch 192/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5386 - accuracy: 0.8433\n",
            "Epoch 193/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5383 - accuracy: 0.8414\n",
            "Epoch 194/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5380 - accuracy: 0.8414\n",
            "Epoch 195/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5378 - accuracy: 0.8414\n",
            "Epoch 196/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5366 - accuracy: 0.8433\n",
            "Epoch 197/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5346 - accuracy: 0.8414\n",
            "Epoch 198/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5365 - accuracy: 0.8375\n",
            "Epoch 199/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5334 - accuracy: 0.8375\n",
            "Epoch 200/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5357 - accuracy: 0.8356\n",
            "Epoch 201/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5343 - accuracy: 0.8433\n",
            "Epoch 202/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5354 - accuracy: 0.8356\n",
            "Epoch 203/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5355 - accuracy: 0.8414\n",
            "Epoch 204/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5348 - accuracy: 0.8395\n",
            "Epoch 205/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5332 - accuracy: 0.8356\n",
            "Epoch 206/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5343 - accuracy: 0.8356\n",
            "Epoch 207/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5345 - accuracy: 0.8375\n",
            "Epoch 208/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5363 - accuracy: 0.8414\n",
            "Epoch 209/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5379 - accuracy: 0.8375\n",
            "Epoch 210/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5339 - accuracy: 0.8395\n",
            "Epoch 211/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5362 - accuracy: 0.8395\n",
            "Epoch 212/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5341 - accuracy: 0.8414\n",
            "Epoch 213/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5395 - accuracy: 0.8375\n",
            "Epoch 214/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5520 - accuracy: 0.8395\n",
            "Epoch 215/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5459 - accuracy: 0.8453\n",
            "Epoch 216/500\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.5486 - accuracy: 0.8375\n",
            "Epoch 217/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.5372 - accuracy: 0.8433\n",
            "Epoch 218/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5353 - accuracy: 0.8395\n",
            "Epoch 219/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5317 - accuracy: 0.8414\n",
            "Epoch 220/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5316 - accuracy: 0.8414\n",
            "Epoch 221/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5318 - accuracy: 0.8375\n",
            "Epoch 222/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5333 - accuracy: 0.8433\n",
            "Epoch 223/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5300 - accuracy: 0.8433\n",
            "Epoch 224/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5317 - accuracy: 0.8414\n",
            "Epoch 225/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5300 - accuracy: 0.8375\n",
            "Epoch 226/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5300 - accuracy: 0.8317\n",
            "Epoch 227/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5316 - accuracy: 0.8337\n",
            "Epoch 228/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5320 - accuracy: 0.8395\n",
            "Epoch 229/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5299 - accuracy: 0.8453\n",
            "Epoch 230/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5306 - accuracy: 0.8356\n",
            "Epoch 231/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5296 - accuracy: 0.8414\n",
            "Epoch 232/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5281 - accuracy: 0.8472\n",
            "Epoch 233/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5296 - accuracy: 0.8414\n",
            "Epoch 234/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5293 - accuracy: 0.8433\n",
            "Epoch 235/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5288 - accuracy: 0.8375\n",
            "Epoch 236/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5289 - accuracy: 0.8433\n",
            "Epoch 237/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5295 - accuracy: 0.8433\n",
            "Epoch 238/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5300 - accuracy: 0.8356\n",
            "Epoch 239/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5270 - accuracy: 0.8472\n",
            "Epoch 240/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5277 - accuracy: 0.8414\n",
            "Epoch 241/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5306 - accuracy: 0.8395\n",
            "Epoch 242/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5390 - accuracy: 0.8375\n",
            "Epoch 243/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5342 - accuracy: 0.8375\n",
            "Epoch 244/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5320 - accuracy: 0.8356\n",
            "Epoch 245/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5328 - accuracy: 0.8395\n",
            "Epoch 246/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5723 - accuracy: 0.8337\n",
            "Epoch 247/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5738 - accuracy: 0.8279\n",
            "Epoch 248/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5638 - accuracy: 0.8317\n",
            "Epoch 249/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5816 - accuracy: 0.8221\n",
            "Epoch 250/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.6062 - accuracy: 0.8221\n",
            "Epoch 251/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5735 - accuracy: 0.8317\n",
            "Epoch 252/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5603 - accuracy: 0.8395\n",
            "Epoch 253/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5391 - accuracy: 0.8414\n",
            "Epoch 254/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5318 - accuracy: 0.8414\n",
            "Epoch 255/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5296 - accuracy: 0.8414\n",
            "Epoch 256/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5295 - accuracy: 0.8337\n",
            "Epoch 257/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5308 - accuracy: 0.8375\n",
            "Epoch 258/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5274 - accuracy: 0.8433\n",
            "Epoch 259/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5280 - accuracy: 0.8433\n",
            "Epoch 260/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5270 - accuracy: 0.8375\n",
            "Epoch 261/500\n",
            "65/65 [==============================] - 1s 17ms/step - loss: 0.5270 - accuracy: 0.8375\n",
            "Epoch 262/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5284 - accuracy: 0.8375\n",
            "Epoch 263/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5261 - accuracy: 0.8337\n",
            "Epoch 264/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5275 - accuracy: 0.8433\n",
            "Epoch 265/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5278 - accuracy: 0.8414\n",
            "Epoch 266/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5289 - accuracy: 0.8337\n",
            "Epoch 267/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5259 - accuracy: 0.8395\n",
            "Epoch 268/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5264 - accuracy: 0.8356\n",
            "Epoch 269/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5256 - accuracy: 0.8414\n",
            "Epoch 270/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5265 - accuracy: 0.8356\n",
            "Epoch 271/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5260 - accuracy: 0.8453\n",
            "Epoch 272/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5271 - accuracy: 0.8375\n",
            "Epoch 273/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5240 - accuracy: 0.8375\n",
            "Epoch 274/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5256 - accuracy: 0.8453\n",
            "Epoch 275/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5260 - accuracy: 0.8375\n",
            "Epoch 276/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5254 - accuracy: 0.8337\n",
            "Epoch 277/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5261 - accuracy: 0.8414\n",
            "Epoch 278/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5261 - accuracy: 0.8375\n",
            "Epoch 279/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5265 - accuracy: 0.8375\n",
            "Epoch 280/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5263 - accuracy: 0.8356\n",
            "Epoch 281/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5270 - accuracy: 0.8414\n",
            "Epoch 282/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5268 - accuracy: 0.8414\n",
            "Epoch 283/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5253 - accuracy: 0.8395\n",
            "Epoch 284/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5263 - accuracy: 0.8433\n",
            "Epoch 285/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5254 - accuracy: 0.8317\n",
            "Epoch 286/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5248 - accuracy: 0.8414\n",
            "Epoch 287/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5258 - accuracy: 0.8433\n",
            "Epoch 288/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5250 - accuracy: 0.8356\n",
            "Epoch 289/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5238 - accuracy: 0.8375\n",
            "Epoch 290/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5265 - accuracy: 0.8356\n",
            "Epoch 291/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5250 - accuracy: 0.8414\n",
            "Epoch 292/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5264 - accuracy: 0.8356\n",
            "Epoch 293/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5279 - accuracy: 0.8356\n",
            "Epoch 294/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5243 - accuracy: 0.8414\n",
            "Epoch 295/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5263 - accuracy: 0.8395\n",
            "Epoch 296/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5257 - accuracy: 0.8375\n",
            "Epoch 297/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5246 - accuracy: 0.8414\n",
            "Epoch 298/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5261 - accuracy: 0.8395\n",
            "Epoch 299/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5248 - accuracy: 0.8414\n",
            "Epoch 300/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5243 - accuracy: 0.8414\n",
            "Epoch 301/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5244 - accuracy: 0.8356\n",
            "Epoch 302/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5251 - accuracy: 0.8414\n",
            "Epoch 303/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5247 - accuracy: 0.8395\n",
            "Epoch 304/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5242 - accuracy: 0.8375\n",
            "Epoch 305/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5272 - accuracy: 0.8337\n",
            "Epoch 306/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5232 - accuracy: 0.8395\n",
            "Epoch 307/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5245 - accuracy: 0.8433\n",
            "Epoch 308/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5242 - accuracy: 0.8375\n",
            "Epoch 309/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5236 - accuracy: 0.8356\n",
            "Epoch 310/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5229 - accuracy: 0.8433\n",
            "Epoch 311/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5238 - accuracy: 0.8395\n",
            "Epoch 312/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5236 - accuracy: 0.8433\n",
            "Epoch 313/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5239 - accuracy: 0.8375\n",
            "Epoch 314/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5227 - accuracy: 0.8375\n",
            "Epoch 315/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5271 - accuracy: 0.8433\n",
            "Epoch 316/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5262 - accuracy: 0.8337\n",
            "Epoch 317/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5268 - accuracy: 0.8453\n",
            "Epoch 318/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5279 - accuracy: 0.8433\n",
            "Epoch 319/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5693 - accuracy: 0.8337\n",
            "Epoch 320/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5698 - accuracy: 0.8337\n",
            "Epoch 321/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5772 - accuracy: 0.8240\n",
            "Epoch 322/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.6135 - accuracy: 0.8221\n",
            "Epoch 323/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5324 - accuracy: 0.8433\n",
            "Epoch 324/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5283 - accuracy: 0.8356\n",
            "Epoch 325/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5262 - accuracy: 0.8337\n",
            "Epoch 326/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5267 - accuracy: 0.8395\n",
            "Epoch 327/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5254 - accuracy: 0.8453\n",
            "Epoch 328/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5232 - accuracy: 0.8395\n",
            "Epoch 329/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5246 - accuracy: 0.8337\n",
            "Epoch 330/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5248 - accuracy: 0.8356\n",
            "Epoch 331/500\n",
            "65/65 [==============================] - 1s 22ms/step - loss: 0.5240 - accuracy: 0.8356\n",
            "Epoch 332/500\n",
            "65/65 [==============================] - 1s 23ms/step - loss: 0.5231 - accuracy: 0.8395\n",
            "Epoch 333/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5241 - accuracy: 0.8433\n",
            "Epoch 334/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5260 - accuracy: 0.8433\n",
            "Epoch 335/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.5239 - accuracy: 0.8395\n",
            "Epoch 336/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5245 - accuracy: 0.8375\n",
            "Epoch 337/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.5229 - accuracy: 0.8395\n",
            "Epoch 338/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5228 - accuracy: 0.8356\n",
            "Epoch 339/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5210 - accuracy: 0.8395\n",
            "Epoch 340/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5248 - accuracy: 0.8414\n",
            "Epoch 341/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8433\n",
            "Epoch 342/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5233 - accuracy: 0.8375\n",
            "Epoch 343/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5227 - accuracy: 0.8375\n",
            "Epoch 344/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5242 - accuracy: 0.8414\n",
            "Epoch 345/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5230 - accuracy: 0.8414\n",
            "Epoch 346/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5229 - accuracy: 0.8356\n",
            "Epoch 347/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5221 - accuracy: 0.8414\n",
            "Epoch 348/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8414\n",
            "Epoch 349/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5223 - accuracy: 0.8395\n",
            "Epoch 350/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5231 - accuracy: 0.8356\n",
            "Epoch 351/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5219 - accuracy: 0.8453\n",
            "Epoch 352/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5224 - accuracy: 0.8375\n",
            "Epoch 353/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5234 - accuracy: 0.8356\n",
            "Epoch 354/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5235 - accuracy: 0.8356\n",
            "Epoch 355/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5219 - accuracy: 0.8375\n",
            "Epoch 356/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5227 - accuracy: 0.8375\n",
            "Epoch 357/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5234 - accuracy: 0.8375\n",
            "Epoch 358/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5235 - accuracy: 0.8395\n",
            "Epoch 359/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5236 - accuracy: 0.8414\n",
            "Epoch 360/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5212 - accuracy: 0.8356\n",
            "Epoch 361/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5221 - accuracy: 0.8414\n",
            "Epoch 362/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5236 - accuracy: 0.8414\n",
            "Epoch 363/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5209 - accuracy: 0.8472\n",
            "Epoch 364/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5210 - accuracy: 0.8395\n",
            "Epoch 365/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5235 - accuracy: 0.8375\n",
            "Epoch 366/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5218 - accuracy: 0.8337\n",
            "Epoch 367/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5235 - accuracy: 0.8414\n",
            "Epoch 368/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.5228 - accuracy: 0.8375\n",
            "Epoch 369/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5229 - accuracy: 0.8395\n",
            "Epoch 370/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5220 - accuracy: 0.8414\n",
            "Epoch 371/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5248 - accuracy: 0.8414\n",
            "Epoch 372/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5428 - accuracy: 0.8337\n",
            "Epoch 373/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5453 - accuracy: 0.8356\n",
            "Epoch 374/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5660 - accuracy: 0.8317\n",
            "Epoch 375/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5389 - accuracy: 0.8375\n",
            "Epoch 376/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5406 - accuracy: 0.8317\n",
            "Epoch 377/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5299 - accuracy: 0.8453\n",
            "Epoch 378/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5270 - accuracy: 0.8414\n",
            "Epoch 379/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5247 - accuracy: 0.8414\n",
            "Epoch 380/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5225 - accuracy: 0.8375\n",
            "Epoch 381/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5230 - accuracy: 0.8356\n",
            "Epoch 382/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5218 - accuracy: 0.8453\n",
            "Epoch 383/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5223 - accuracy: 0.8414\n",
            "Epoch 384/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5238 - accuracy: 0.8337\n",
            "Epoch 385/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5236 - accuracy: 0.8317\n",
            "Epoch 386/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5234 - accuracy: 0.8433\n",
            "Epoch 387/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5215 - accuracy: 0.8433\n",
            "Epoch 388/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5206 - accuracy: 0.8433\n",
            "Epoch 389/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8298\n",
            "Epoch 390/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5211 - accuracy: 0.8414\n",
            "Epoch 391/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.5244 - accuracy: 0.8375\n",
            "Epoch 392/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5245 - accuracy: 0.8356\n",
            "Epoch 393/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5219 - accuracy: 0.8375\n",
            "Epoch 394/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5213 - accuracy: 0.8433\n",
            "Epoch 395/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.5215 - accuracy: 0.8356\n",
            "Epoch 396/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5228 - accuracy: 0.8414\n",
            "Epoch 397/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5212 - accuracy: 0.8433\n",
            "Epoch 398/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8414\n",
            "Epoch 399/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5201 - accuracy: 0.8395\n",
            "Epoch 400/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5219 - accuracy: 0.8375\n",
            "Epoch 401/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8375\n",
            "Epoch 402/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5224 - accuracy: 0.8414\n",
            "Epoch 403/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5221 - accuracy: 0.8375\n",
            "Epoch 404/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5215 - accuracy: 0.8375\n",
            "Epoch 405/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5194 - accuracy: 0.8395\n",
            "Epoch 406/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8337\n",
            "Epoch 407/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5209 - accuracy: 0.8433\n",
            "Epoch 408/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5217 - accuracy: 0.8395\n",
            "Epoch 409/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5222 - accuracy: 0.8414\n",
            "Epoch 410/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5207 - accuracy: 0.8395\n",
            "Epoch 411/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5199 - accuracy: 0.8453\n",
            "Epoch 412/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5229 - accuracy: 0.8375\n",
            "Epoch 413/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5230 - accuracy: 0.8395\n",
            "Epoch 414/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5215 - accuracy: 0.8375\n",
            "Epoch 415/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5217 - accuracy: 0.8298\n",
            "Epoch 416/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5209 - accuracy: 0.8395\n",
            "Epoch 417/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5225 - accuracy: 0.8395\n",
            "Epoch 418/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5273 - accuracy: 0.8356\n",
            "Epoch 419/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5495 - accuracy: 0.8395\n",
            "Epoch 420/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5530 - accuracy: 0.8395\n",
            "Epoch 421/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5453 - accuracy: 0.8317\n",
            "Epoch 422/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5306 - accuracy: 0.8356\n",
            "Epoch 423/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5222 - accuracy: 0.8433\n",
            "Epoch 424/500\n",
            "65/65 [==============================] - 1s 11ms/step - loss: 0.5234 - accuracy: 0.8395\n",
            "Epoch 425/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5230 - accuracy: 0.8337\n",
            "Epoch 426/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5213 - accuracy: 0.8395\n",
            "Epoch 427/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5215 - accuracy: 0.8472\n",
            "Epoch 428/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5222 - accuracy: 0.8317\n",
            "Epoch 429/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5223 - accuracy: 0.8414\n",
            "Epoch 430/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5219 - accuracy: 0.8395\n",
            "Epoch 431/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5204 - accuracy: 0.8375\n",
            "Epoch 432/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5210 - accuracy: 0.8395\n",
            "Epoch 433/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5212 - accuracy: 0.8414\n",
            "Epoch 434/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8337\n",
            "Epoch 435/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5204 - accuracy: 0.8472\n",
            "Epoch 436/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5201 - accuracy: 0.8395\n",
            "Epoch 437/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5218 - accuracy: 0.8356\n",
            "Epoch 438/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5218 - accuracy: 0.8453\n",
            "Epoch 439/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5225 - accuracy: 0.8433\n",
            "Epoch 440/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5215 - accuracy: 0.8395\n",
            "Epoch 441/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5213 - accuracy: 0.8395\n",
            "Epoch 442/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5200 - accuracy: 0.8414\n",
            "Epoch 443/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5209 - accuracy: 0.8375\n",
            "Epoch 444/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5208 - accuracy: 0.8395\n",
            "Epoch 445/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8395\n",
            "Epoch 446/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5207 - accuracy: 0.8395\n",
            "Epoch 447/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5215 - accuracy: 0.8337\n",
            "Epoch 448/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5206 - accuracy: 0.8356\n",
            "Epoch 449/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5194 - accuracy: 0.8433\n",
            "Epoch 450/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5215 - accuracy: 0.8414\n",
            "Epoch 451/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5196 - accuracy: 0.8433\n",
            "Epoch 452/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5217 - accuracy: 0.8356\n",
            "Epoch 453/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5197 - accuracy: 0.8453\n",
            "Epoch 454/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5201 - accuracy: 0.8375\n",
            "Epoch 455/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5206 - accuracy: 0.8356\n",
            "Epoch 456/500\n",
            "65/65 [==============================] - 1s 15ms/step - loss: 0.5191 - accuracy: 0.8395\n",
            "Epoch 457/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5215 - accuracy: 0.8375\n",
            "Epoch 458/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5215 - accuracy: 0.8414\n",
            "Epoch 459/500\n",
            "65/65 [==============================] - 1s 16ms/step - loss: 0.5198 - accuracy: 0.8433\n",
            "Epoch 460/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5206 - accuracy: 0.8453\n",
            "Epoch 461/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5239 - accuracy: 0.8395\n",
            "Epoch 462/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5233 - accuracy: 0.8375\n",
            "Epoch 463/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5208 - accuracy: 0.8356\n",
            "Epoch 464/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5215 - accuracy: 0.8375\n",
            "Epoch 465/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5190 - accuracy: 0.8472\n",
            "Epoch 466/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5206 - accuracy: 0.8375\n",
            "Epoch 467/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5207 - accuracy: 0.8414\n",
            "Epoch 468/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5216 - accuracy: 0.8375\n",
            "Epoch 469/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5201 - accuracy: 0.8375\n",
            "Epoch 470/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5186 - accuracy: 0.8433\n",
            "Epoch 471/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5220 - accuracy: 0.8414\n",
            "Epoch 472/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5209 - accuracy: 0.8356\n",
            "Epoch 473/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5189 - accuracy: 0.8414\n",
            "Epoch 474/500\n",
            "65/65 [==============================] - 1s 18ms/step - loss: 0.5213 - accuracy: 0.8433\n",
            "Epoch 475/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5193 - accuracy: 0.8356\n",
            "Epoch 476/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5196 - accuracy: 0.8375\n",
            "Epoch 477/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5194 - accuracy: 0.8375\n",
            "Epoch 478/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5199 - accuracy: 0.8433\n",
            "Epoch 479/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5208 - accuracy: 0.8375\n",
            "Epoch 480/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5196 - accuracy: 0.8375\n",
            "Epoch 481/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5199 - accuracy: 0.8356\n",
            "Epoch 482/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5196 - accuracy: 0.8356\n",
            "Epoch 483/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5197 - accuracy: 0.8356\n",
            "Epoch 484/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5190 - accuracy: 0.8414\n",
            "Epoch 485/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5173 - accuracy: 0.8414\n",
            "Epoch 486/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5208 - accuracy: 0.8337\n",
            "Epoch 487/500\n",
            "65/65 [==============================] - 1s 17ms/step - loss: 0.5194 - accuracy: 0.8395\n",
            "Epoch 488/500\n",
            "65/65 [==============================] - 1s 20ms/step - loss: 0.5270 - accuracy: 0.8395\n",
            "Epoch 489/500\n",
            "65/65 [==============================] - 1s 19ms/step - loss: 0.5263 - accuracy: 0.8395\n",
            "Epoch 490/500\n",
            "65/65 [==============================] - 1s 14ms/step - loss: 0.5286 - accuracy: 0.8356\n",
            "Epoch 491/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5769 - accuracy: 0.8240\n",
            "Epoch 492/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5748 - accuracy: 0.8298\n",
            "Epoch 493/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5295 - accuracy: 0.8375\n",
            "Epoch 494/500\n",
            "65/65 [==============================] - 1s 13ms/step - loss: 0.5232 - accuracy: 0.8395\n",
            "Epoch 495/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5224 - accuracy: 0.8337\n",
            "Epoch 496/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5204 - accuracy: 0.8453\n",
            "Epoch 497/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5199 - accuracy: 0.8414\n",
            "Epoch 498/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5190 - accuracy: 0.8472\n",
            "Epoch 499/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5205 - accuracy: 0.8395\n",
            "Epoch 500/500\n",
            "65/65 [==============================] - 1s 12ms/step - loss: 0.5204 - accuracy: 0.8433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot utility\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the accuracy\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "5Pr3m3IOoUG6",
        "outputId": "4b839a8b-41df-4ddc-843b-bdf391f94511"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict the words for test sentence"
      ],
      "metadata": {
        "id": "9mseYJJWpAdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Sai went to Dublin\"\n",
        "\n",
        "seed_token = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "padded_seed_token = pad_sequences([seed_token], maxlen=max_seq_len-1, padding=\"pre\")\n",
        "padded_seed_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYUAwetyotwr",
        "outputId": "efd9e742-7e3e-433b-ee64-6338530d9253"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0, 134,  13,  59]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(padded_seed_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05fF4unY50dk",
        "outputId": "f3948bb6-a1b0-48b1-cc9e-4d9e3c2ab1f2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(y_pred, axis=-1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVDSbfO97OXV",
        "outputId": "ff8e3ddd-dea2-4f4c-a70c-317b4cac4bfa"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.index_word.get((np.argmax(y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nZMcIvNK6A8H",
        "outputId": "fe4325ef-cdab-49ad-c2d1-9ecc99628218"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.index_word.get(np.argmax(model.predict(padded_seed_token)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Qo1r6IkI7rF5",
        "outputId": "102b820e-c3d3-4289-8e11-637abdcbda77"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = 10\n",
        "seed_text = \"Sai went to Dublin\"\n",
        "\n",
        "for i in range(num_words):\n",
        "  seed_token = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  padded_seed_token = pad_sequences([seed_token], maxlen=max_seq_len-1, padding=\"pre\")\n",
        "  #padded_seed_token\n",
        "  y_prob = model.predict(padded_seed_token)\n",
        "  Y_pred = tokenizer.index_word.get((np.argmax(y_prob)))\n",
        "\n",
        "  if np.argmax(y_prob) != 0: #0 is  is 0 because that is just the padding.\n",
        "    print(Y_pred)\n",
        "    seed_text += \" \" + Y_pred\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91GZUO3P6cm_",
        "outputId": "f6810417-1da0-46a0-afde-e093693087d7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "all\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "around\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "in\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "couples\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "and\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "groups\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "groups\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "relations\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "old\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "hall\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q-3pibH37GS8",
        "outputId": "6013f543-5a33-4e89-9b46-923f0ae25a81"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sai went to Dublin all around in couples and groups groups relations old hall'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xCdPUQ6Y8Cvw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}