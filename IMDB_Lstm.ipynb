{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJCmxWp9Toew/NWm6wLX+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sundar-nallalagappan/Coursera_NLP_assignments/blob/main/IMDB_Lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOMRZvPiTh5G",
        "outputId": "191831e4-264b-45bc-eec8-16b2a132a89d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sairam\n"
          ]
        }
      ],
      "source": [
        "print(\"sairam\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the IMDB use case using Bi-directional LSTM"
      ],
      "metadata": {
        "id": "KRDGOPlLTl7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Dense, Flatten, GlobalAveragePooling1D, LSTM, Bidirectional, Embedding\n",
        "from keras.models import Sequential\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "fmmXNSMETlhc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "jqAo_TZaU6hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb, info = tfds.load(\"imdb_reviews/subwords8k\", with_info=True, as_supervised=True)\n",
        "imdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tuL6EAdTxi4",
        "outputId": "56c4e8cd-e590-42a5-c283-e96156a313bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
              " 'test': <_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
              " 'unsupervised': <_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_subwords = info.features['text'].encoder"
      ],
      "metadata": {
        "id": "dUoluPrgVDDy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = imdb['train'], imdb['test']\n",
        "\n",
        "for row in train:\n",
        "  print(row)\n",
        "  break\n",
        "\n",
        "for row in test:\n",
        "  print(row)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmtdGR4oXRnC",
        "outputId": "53895aa0-c6cb-4075-d3b2-bb2d8ed5b9fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(163,), dtype=int64, numpy=\n",
            "array([  62,   18,   41,  604,  927,   65,    3,  644, 7968,   21,   35,\n",
            "       5096,   36,   11,   43, 2948, 5240,  102,   50,  681, 7862, 1244,\n",
            "          3, 3266,   29,  122,  640,    2,   26,   14,  279,  438,   35,\n",
            "         79,  349,  384,   11, 1991,    3,  492,   79,  122,  188,  117,\n",
            "         33, 4047, 4531,   14,   65, 7968,    8, 1819, 3947,    3,   62,\n",
            "         27,    9,   41,  577, 5044, 2629, 2552, 7193, 7961, 3642,    3,\n",
            "         19,  107, 3903,  225,   85,  198,   72,    1, 1512,  738, 2347,\n",
            "        102, 6245,    8,   85,  308,   79, 6936, 7961,   23, 4981, 8044,\n",
            "          3, 6429, 7961, 1141, 1335, 1848, 4848,   55, 3601, 4217, 8050,\n",
            "          2,    5,   59, 3831, 1484, 8040, 7974,  174, 5773,   22, 5240,\n",
            "        102,   18,  247,   26,    4, 3903, 1612, 3902,  291,   11,    4,\n",
            "         27,   13,   18, 4092, 4008, 7961,    6,  119,  213, 2774,    3,\n",
            "         12,  258, 2306,   13,   91,   29,  171,   52,  229,    2, 1245,\n",
            "       5790,  995, 7968,    8,   52, 2948, 5240, 8039, 7968,    8,   74,\n",
            "       1249,    3,   12,  117, 2438, 1369,  192,   39, 7975])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
            "(<tf.Tensor: shape=(283,), dtype=int64, numpy=\n",
            "array([ 173,   29,  185,   13,  115, 1956, 8044,    3,  398, 1261, 5497,\n",
            "        423,    2,   15,   18, 4096, 3958,  637, 2657,  552, 2893, 4926,\n",
            "       2314, 1673, 4587,  137,   23, 4872, 5345,    2, 7996, 7277, 8004,\n",
            "       8012,  137,   23,  972, 5346, 5977, 1365, 8051,    2, 7998, 3780,\n",
            "       1947, 1747, 4411, 3743,    3, 5064, 7961,    7,   13, 2671, 4556,\n",
            "       3449, 1678,  572, 8037, 7968,    8,  604, 1006, 4002, 2618, 7974,\n",
            "       7994, 7974, 2893, 2618, 7974, 2475, 3912,    3, 4847, 2034, 2615,\n",
            "         66, 7974, 3201,    2,    5,   20, 1668, 5475, 7961,    5,   20,\n",
            "       4474,   20,  119,    6,    1, 2489, 1473, 1960,  323,    3,   12,\n",
            "       1167, 7968,   21, 4101,   14,  366,  342,   12,  284,  552, 7999,\n",
            "       4949, 3780, 3779, 3369, 8018,  625, 1979,    2,   78, 1259,    2,\n",
            "         12,  109, 7968,   21,  129,   12, 4101,  236,   14, 1682,  230,\n",
            "        392,    7, 4980, 1079, 1678,  572, 8037, 7968,    8, 1712,    9,\n",
            "       5795,  535,  106, 4002, 2618, 7974, 7994, 7974, 2893, 2618, 7974,\n",
            "       2475, 3912, 7961,    9,   55, 1296,  488,  569,    6, 5852, 1125,\n",
            "        272, 2148, 7961,   13,   45,   70,   31,    7, 1369,  267,   22,\n",
            "          4, 2346,    6,   14,  397,    5,  110,    4,  918, 7974, 1134,\n",
            "       7974,  557, 7716,  452,    6,   15,    7,  765, 2284,  181,    2,\n",
            "       8046, 8033,    2, 2144, 1077,  395,    5, 1060, 8029,  395,    6,\n",
            "         39,    3, 2478,  516,    9, 3499, 5991, 8029,   28,    4, 1250,\n",
            "       6148,    6,    4, 2479, 7974, 5884, 7961,  575,  152,    5,    1,\n",
            "        695,   51,  268,   29, 6749, 8029,   28,  224, 7968,    8, 1400,\n",
            "          6,    1,  362, 7974,  181, 7974,  609, 5353,  923, 2117,   45,\n",
            "       7399, 2331, 7968,  123, 1974,   48,    4,   32,   52,  229,  158,\n",
            "       4002, 2618, 7974, 7994, 7974, 2893, 2618, 7974, 2475, 3912, 7961,\n",
            "          9,    4,   32,  901,  101,   57, 1868, 7975])>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in train:\n",
        "  print(tokenizer_subwords.decode(row[0]))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVabovqQXeF9",
        "outputId": "82aef9f3-f2bc-4af0-d8b5-e0041ae29105"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* padded_batch function - will padd the sequences and also put them in requested batches"
      ],
      "metadata": {
        "id": "vGsrI3G4YUIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE  = 256\n",
        "\n",
        "train_dataset = train.shuffle(BUFFER_SIZE)\n",
        "\n",
        "train_dataset = train.padded_batch(BATCH_SIZE)\n",
        "test_dataset  = test.padded_batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "svL8LFJkX1a5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, i in enumerate(train_dataset):\n",
        "  print(idx)\n",
        "  if idx < 4:\n",
        "    print(i[0])\n",
        "    print(i[0].shape)\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTznZWr1YsaR",
        "outputId": "27631fc4-d1ac-4ff6-b304-f970bc80fc33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "tf.Tensor(\n",
            "[[  62   18   41 ...    0    0    0]\n",
            " [  12   31   93 ...    0    0    0]\n",
            " [ 636  102 4714 ...    0    0    0]\n",
            " ...\n",
            " [  19   77  457 ...    0    0    0]\n",
            " [5440  131 5617 ...    0    0    0]\n",
            " [3475  456  143 ...    0    0    0]], shape=(256, 1179), dtype=int64)\n",
            "(256, 1179)\n",
            "1\n",
            "tf.Tensor(\n",
            "[[  19   27   18 ...    0    0    0]\n",
            " [7914    4 3572 ...    0    0    0]\n",
            " [ 133 2690 1083 ...    0    0    0]\n",
            " ...\n",
            " [1987    2   14 ...    0    0    0]\n",
            " [ 156   37  239 ...    0    0    0]\n",
            " [1097 3837 7961 ...    0    0    0]], shape=(256, 1615), dtype=int64)\n",
            "(256, 1615)\n",
            "2\n",
            "tf.Tensor(\n",
            "[[  19   32 1422 ...    0    0    0]\n",
            " [  12  988 1415 ...    0    0    0]\n",
            " [3209 1493    5 ...    0    0    0]\n",
            " ...\n",
            " [7627   20  979 ...    0    0    0]\n",
            " [  12  800  359 ...    0    0    0]\n",
            " [  12   31   33 ...    0    0    0]], shape=(256, 1485), dtype=int64)\n",
            "(256, 1485)\n",
            "3\n",
            "tf.Tensor(\n",
            "[[4878 1624    4 ...    0    0    0]\n",
            " [  12 3059 5086 ...    0    0    0]\n",
            " [ 699 3320  319 ...    0    0    0]\n",
            " ...\n",
            " [  12  772 2135 ...    0    0    0]\n",
            " [  62   18  273 ...    0    0    0]\n",
            " [ 713 7053 7961 ...    0    0    0]], shape=(256, 1470), dtype=int64)\n",
            "(256, 1470)\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i[0][0].numpy().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTV66dHYYtM0",
        "outputId": "7138dec7-206b-4f84-ce02-a7c5f1bbd4ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1497,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i[0].numpy().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FPqVTc-bMa_",
        "outputId": "ad97f2d2-0c4b-4852-90aa-b3ab08514f15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 1497)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Not clear for me, when we apply padded_batch, the length is varying then how come it is accepted by NN"
      ],
      "metadata": {
        "id": "TTyJlrXQZngw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build & compile model"
      ],
      "metadata": {
        "id": "Zvb-ZZY1cJkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_subwords.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQJGZbKkcV2I",
        "outputId": "fea6aa28-0648-4ff8-fb9c-62315eafb300"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8185"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_SIZE=64"
      ],
      "metadata": {
        "id": "sY_8NVCmccAW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(tokenizer_subwords.vocab_size, EMBED_SIZE),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(64, \"relu\"),\n",
        "    Dense(1, \"sigmoid\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqzK5i4_cHx6",
        "outputId": "aafee6be-cba2-442b-91a8-a8399f972a44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          523840    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 598,209\n",
            "Trainable params: 598,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rXVShJ18cHvX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, validation_data=test_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PztNurmucHss",
        "outputId": "05f88f82-40ae-4ef8-d8d6-d4f7ba518e7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "98/98 [==============================] - 52s 438ms/step - loss: 0.6401 - accuracy: 0.6234 - val_loss: 0.4556 - val_accuracy: 0.7892\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 20s 206ms/step - loss: 0.3635 - accuracy: 0.8448 - val_loss: 0.4183 - val_accuracy: 0.8169\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 20s 207ms/step - loss: 0.2842 - accuracy: 0.8870 - val_loss: 0.4472 - val_accuracy: 0.8320\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 21s 213ms/step - loss: 0.2478 - accuracy: 0.9059 - val_loss: 0.4709 - val_accuracy: 0.8378\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 25s 260ms/step - loss: 0.2175 - accuracy: 0.9182 - val_loss: 0.5031 - val_accuracy: 0.8163\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 21s 213ms/step - loss: 0.2051 - accuracy: 0.9225 - val_loss: 0.5988 - val_accuracy: 0.7726\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.1701 - accuracy: 0.9366 - val_loss: 0.5719 - val_accuracy: 0.8070\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.1548 - accuracy: 0.9449 - val_loss: 0.6137 - val_accuracy: 0.8132\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.1478 - accuracy: 0.9475 - val_loss: 0.6622 - val_accuracy: 0.8178\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 21s 209ms/step - loss: 0.1322 - accuracy: 0.9544 - val_loss: 0.7064 - val_accuracy: 0.8192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fea3482d5a0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZregT8ghcHoU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "diKST-8tcHkW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = []\n",
        "train_labels    = []\n",
        "\n",
        "test_sentences  = []\n",
        "test_labels     = []\n",
        "\n",
        "for row in train:\n",
        "  train_sentences.append(row[0].numpy())\n",
        "  train_labels.append(row[1].numpy())\n",
        "\n",
        "\n",
        "for row in test:\n",
        "  test_sentences.append(row[0].numpy())\n",
        "  test_labels.append(row[1].numpy())"
      ],
      "metadata": {
        "id": "XYMJt_FFZUPV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NqLWj6caHq5",
        "outputId": "f040d067-a873-4cd5-f5ca-d0e29d6deb2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  62,   18,   41,  604,  927,   65,    3,  644, 7968,   21,   35,\n",
              "       5096,   36,   11,   43, 2948, 5240,  102,   50,  681, 7862, 1244,\n",
              "          3, 3266,   29,  122,  640,    2,   26,   14,  279,  438,   35,\n",
              "         79,  349,  384,   11, 1991,    3,  492,   79,  122,  188,  117,\n",
              "         33, 4047, 4531,   14,   65, 7968,    8, 1819, 3947,    3,   62,\n",
              "         27,    9,   41,  577, 5044, 2629, 2552, 7193, 7961, 3642,    3,\n",
              "         19,  107, 3903,  225,   85,  198,   72,    1, 1512,  738, 2347,\n",
              "        102, 6245,    8,   85,  308,   79, 6936, 7961,   23, 4981, 8044,\n",
              "          3, 6429, 7961, 1141, 1335, 1848, 4848,   55, 3601, 4217, 8050,\n",
              "          2,    5,   59, 3831, 1484, 8040, 7974,  174, 5773,   22, 5240,\n",
              "        102,   18,  247,   26,    4, 3903, 1612, 3902,  291,   11,    4,\n",
              "         27,   13,   18, 4092, 4008, 7961,    6,  119,  213, 2774,    3,\n",
              "         12,  258, 2306,   13,   91,   29,  171,   52,  229,    2, 1245,\n",
              "       5790,  995, 7968,    8,   52, 2948, 5240, 8039, 7968,    8,   74,\n",
              "       1249,    3,   12,  117, 2438, 1369,  192,   39, 7975])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_sentences), type(train_sentences[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi-1xFDbp_15",
        "outputId": "1357817d-395e-4a95-c93f-99ef44524fb8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEwf-39maVPi",
        "outputId": "b0e93be5-66fb-4a5a-b849-8c35ed3a236b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  12,   31,   93,  867,    7, 1256, 6585, 7961,  421,  365,    2,\n",
              "         26,   14,    9,  988, 1089,    7,    4, 6728,    6,  276, 5760,\n",
              "       2587,    2,   81, 6118, 8029,    2,  139, 1892, 7961,    5, 5402,\n",
              "        246,   25,    1, 1771,  350,    5,  369,   56, 5397,  102,    4,\n",
              "       2547,    3, 4001,   25,   14, 7822,  209,   12, 3531, 6585, 7961,\n",
              "         99,    1,   32,   18, 4762,    3,   19,  184, 3223,   18, 5855,\n",
              "       1045,    3, 4232, 3337,   64, 1347,    5, 1190,    3, 4459,    8,\n",
              "        614,    7, 3129,    2,   26,   22,   84, 7020,    6,   71,   18,\n",
              "       4924, 1160,  161,   50, 2265,    3,   12, 3983,    2,   12,  264,\n",
              "         31, 2545,  261,    6,    1,   66,    2,   26,  131,  393,    1,\n",
              "       5846,    6,   15,    5,  473,   56,  614,    7, 1470,    6,  116,\n",
              "        285, 4755, 2088, 7961,  273,  119,  213, 3414, 7961,   23,  332,\n",
              "       1019,    3,   12, 7667,  505,   14,   32,   44,  208, 7975])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-sMRuGYqG6J",
        "outputId": "0e92a5cb-a968-4a35-8c92-72945564aa30"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "DBAWFnT-qMZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_sentences_fin = np.array(train_sentences)\n",
        "#test_sentences_fin  = np.array(test_sentences)\n",
        "\n",
        "#train_labels_fin = np.array(train_labels)\n",
        "#test_labels_fin  = np.array(test_labels)"
      ],
      "metadata": {
        "id": "7AqBOwqta-fZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import pad_sequences\n",
        "train_padded = pad_sequences(train_sentences, maxlen=1500, padding=\"post\", truncating=\"post\")\n",
        "test_padded  = pad_sequences(test_sentences, maxlen=1500, padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "UbEk5OEqmP3x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l-LyLLVmZwJ",
        "outputId": "2954dacc-167e-4879-c1a7-aa8021a80935"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 1500)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_padded[0]), len(train_padded[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2jkOSnMm9kH",
        "outputId": "11f3353d-d801-4c07-ccc8-5f6b1137605b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 1500)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(tokenizer_subwords.vocab_size, EMBED_SIZE),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(64, \"relu\"),\n",
        "    Dense(1, \"sigmoid\")\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_padded, np.array(train_labels), validation_data=(test_padded, np.array(test_labels)), epochs=10, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0EKAYPFnHxb",
        "outputId": "02b3ebae-02f4-4d14-c957-dee8524ba5a1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 64)          523840    \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 128)              66048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 598,209\n",
            "Trainable params: 598,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "98/98 [==============================] - 35s 320ms/step - loss: 0.5811 - accuracy: 0.6817 - val_loss: 0.4475 - val_accuracy: 0.8153\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 33s 340ms/step - loss: 0.3571 - accuracy: 0.8563 - val_loss: 0.4377 - val_accuracy: 0.8078\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 25s 254ms/step - loss: 0.2793 - accuracy: 0.8948 - val_loss: 0.4146 - val_accuracy: 0.8290\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 24s 243ms/step - loss: 0.2426 - accuracy: 0.9108 - val_loss: 0.4076 - val_accuracy: 0.8373\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.1966 - accuracy: 0.9285 - val_loss: 0.4215 - val_accuracy: 0.8218\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 22s 219ms/step - loss: 0.1662 - accuracy: 0.9430 - val_loss: 0.4317 - val_accuracy: 0.8452\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 21s 211ms/step - loss: 0.1483 - accuracy: 0.9480 - val_loss: 0.5833 - val_accuracy: 0.7378\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 21s 215ms/step - loss: 0.1659 - accuracy: 0.9389 - val_loss: 0.5217 - val_accuracy: 0.8206\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 21s 212ms/step - loss: 0.1092 - accuracy: 0.9628 - val_loss: 0.5368 - val_accuracy: 0.8241\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 20s 208ms/step - loss: 0.1040 - accuracy: 0.9652 - val_loss: 0.5927 - val_accuracy: 0.8208\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f195f64c640>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKpl6No3qg6l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}